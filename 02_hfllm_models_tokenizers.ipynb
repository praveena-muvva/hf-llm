{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjTfxIKCj5tcLhv6783i3e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveena-muvva/hf-llm/blob/main/02_hfllm_models_tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18Th1oIVMs1A"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('huggingface')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel #AutoModel is a simple weapper and can fetch the appropriate model architecture\n",
        "#If you know the type of model, you can directly use it: import BertModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"bert-base-cased\") #This will download and cache the model data from HF hub\n",
        "model.save_pretrained(\"\") #saves model weights and architecture config (config.json, model.safetensors)"
      ],
      "metadata": {
        "id": "2fbqRiedM1cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding text\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_input = tokenizer(\"Hello, how are you?\")\n",
        "print(encoded_input) #Contains input_ids, token_type_ids, attention_mask"
      ],
      "metadata": {
        "id": "A11DPOFWOdHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoding input ids to get back the original text\n",
        "tokenizer.decode(encoded_input[\"input_ids\"])\n",
        "\n",
        "#[CLS] Hello, how are you? [SEP]\n",
        "#tokenizer will add special tokens\n",
        "\n",
        "#Can further use padding, truncate to adjust the size or sentences"
      ],
      "metadata": {
        "id": "iEXHM327Ov2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizers - split the raw text into words and find a numerical representation for each of them\n",
        "#sub-word token is usually efficient compared to complete word or character based considering all scenarios\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "sequence = \"Let's build a large language model using tranformers\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "NAQxeSpdPC8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd step is to convert the tokens into numbers and build tensor out of them to feed to the model\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ],
      "metadata": {
        "id": "xXzY0Y2MSNHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoding\n",
        "decoded_string = tokenizer.decode([2421, 112, 188, 3076, 170, 1415, 1846, 2235, 1606, 189, 4047, 23763, 1116]) #output of previous step\n",
        "print(decoded_string) #your original string"
      ],
      "metadata": {
        "id": "r5tEsMwcTBIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2eCNCvllTNgd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}